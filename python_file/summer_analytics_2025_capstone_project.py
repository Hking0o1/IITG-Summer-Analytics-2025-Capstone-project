# -*- coding: utf-8 -*-
"""Summer_Analytics_2025_Capstone_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Z5wMsNT0kah_jZ85sSEN1yXL-w2kV0E

# IITG SUMMER Analytics 2025 Capstone Project
## Dynamic Pricing of Urban Parking Lots

### 1. Data Preprocessing and cleaning
"""

!pip install pandas numpy matplotlib seaborn -q

# Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load Dataset
df = pd.read_csv("/content/dataset.csv")
print("Initial shape:", df.shape)
df.dropna(inplace=True)

# Combine Date and Time into a single datetime column
df['Timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'], format='%d-%m-%Y %H:%M:%S')
df.drop(columns=['LastUpdatedDate', 'LastUpdatedTime'], inplace=True)

# Encode Categorical Columns
df['VehicleTypeEncoded'] = df['VehicleType'].map({'car': 0, 'bike': 1, 'truck': 2, 'cycle': 3})
df['TrafficEncoded'] = df['TrafficConditionNearby'].map({'Low': 0, 'Medium': 1, 'High': 2, 'average': 1})

"""### 2. EDA"""

print("\nUnique Parking Spaces:", df['SystemCodeNumber'].nunique())

"""**1. Occupancy Distribution**"""

plt.figure(figsize=(8, 4))
sns.histplot(df['Occupancy'], bins=30, kde=True)
plt.title("Occupancy Distribution")
plt.xlabel("Occupancy")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""**2. Occupancy vs Capacity**"""

plt.figure(figsize=(8, 4))
sns.scatterplot(data=df, x='Capacity', y='Occupancy', hue='VehicleType')
plt.title("Occupancy vs Capacity by Vehicle Type")
plt.grid(True)
plt.show()

"""**3. Occupancy Trend Over Time for a Sample**"""

sample_lot = df['SystemCodeNumber'].unique()[0]
sample_df = df[df['SystemCodeNumber'] == sample_lot]

plt.figure(figsize=(12, 4))
plt.plot(sample_df['Timestamp'], sample_df['Occupancy'], label=f"Lot {sample_lot}")
plt.title("Occupancy Over Time (Sample Lot)")
plt.xlabel("Time")
plt.ylabel("Occupancy")
plt.grid(True)
plt.legend()
plt.show()

"""**4. Heatmap of Feature Correlations**"""

corr = df[['Occupancy', 'QueueLength', 'TrafficEncoded', 'IsSpecialDay', 'VehicleTypeEncoded']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Feature Correlation Matrix")
plt.show()

"""### Save Preprocessed Data for Modeling"""

df.to_csv("preprocessed_dataset.csv", index=False)

"""##Model 1 Overview ‚Äî Linear Pricing
###Formula:

####Priceùë°+1 = Priceùë° + ùõº‚ãÖ(Occupancy / Capacity)


*  Starts from a base price of $10

*   Prices should be bounded, e.g., $5 ‚â§ price ‚â§ $20

*   Smooth variation using a small Œ±, e.g., Œ± = 2


"""

def linear_pricing_model(df, alpha=2, base_price=10, min_price=5, max_price=20):
    """
    Calculates price over time using a simple linear pricing rule.

    Args:
        df (DataFrame): Preprocessed dataset
        alpha (float): Sensitivity factor for price adjustment
        base_price (float): Starting price
        min_price (float): Minimum price bound
        max_price (float): Maximum price bound

    Returns:
        DataFrame: With added 'Price' column
    """

    df = df.sort_values(['SystemCodeNumber', 'Timestamp']).copy()
    df['Price'] = 0.0

    for lot in df['SystemCodeNumber'].unique():
        lot_df = df[df['SystemCodeNumber'] == lot].copy()
        price = base_price
        prices = []

        for _, row in lot_df.iterrows():
            occupancy_ratio = row['Occupancy'] / row['Capacity']
            price += alpha * occupancy_ratio
            price = max(min_price, min(max_price, price))  # Clamp within bounds
            prices.append(price)

        df.loc[df['SystemCodeNumber'] == lot, 'Price'] = prices

    return df

# Run the model if this script is called directly
if __name__ == "__main__":
    df = pd.read_csv("preprocessed_dataset.csv", parse_dates=['Timestamp'])
    df = linear_pricing_model(df)

    # Save for later models/visualizations
    df.to_csv("baseline_pricing_output.csv", index=False)

    # Optional: Visualize one parking lot
    sample_lot = df['SystemCodeNumber'].unique()[0]
    sample_df = df[df['SystemCodeNumber'] == sample_lot]

    plt.figure(figsize=(12, 4))
    plt.plot(sample_df['Timestamp'], sample_df['Price'], label='Price ($)')
    plt.title(f"Baseline Pricing Over Time (Lot {sample_lot})")
    plt.xlabel("Time")
    plt.ylabel("Price ($)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

df = pd.read_csv("preprocessed_dataset.csv", parse_dates=['Timestamp'])
result_df = linear_pricing_model(df)

"""##Model 2 Overview ‚Äî Demand-Based Pricing

###Demand Function:

* Demand=Œ±‚ãÖ(Occupancy / Capacity)+Œ≤‚ãÖQueueLength‚àíŒ≥‚ãÖTraffic+Œ¥‚ãÖIsSpecialDay+Œµ‚ãÖVehicleTypeWeight

Then:

*  Priceùë°=BasePrice‚ãÖ(1+ùúÜ‚ãÖNormalizedDemand)
"""

from sklearn.preprocessing import MinMaxScaler
import pandas as pd

def compute_demand(df, weights):
    """Compute raw demand score using weighted features"""

    # Fill any remaining non-numeric values (like empty strings) with 0 before conversion
    df['TrafficEncoded'] = pd.to_numeric(df['TrafficEncoded'], errors='coerce').fillna(0)
    vt_weight = pd.to_numeric(df['VehicleTypeEncoded'].map({0: 1.0, 1: 0.6, 2: 1.2, 3: 0.5}), errors='coerce').fillna(0)

    demand = (
        weights['alpha'] * (df['Occupancy'] / df['Capacity']) +
        weights['beta']  * df['QueueLength'] +
        weights['gamma'] * df['TrafficEncoded'] +
        weights['delta'] * df['IsSpecialDay'] +
        weights['epsilon'] * vt_weight
    )
    return demand

def normalize_demand(demand_series):
    """Normalize demand to [0, 1]"""
    scaler = MinMaxScaler()
    demand_reshaped = demand_series.values.reshape(-1, 1)
    return scaler.fit_transform(demand_reshaped).flatten()

def demand_pricing_model(df, base_price=10, lambda_coeff=0.5):
    """Applies demand-based pricing logic"""
    df = df.sort_values(['SystemCodeNumber', 'Timestamp']).copy()

    # Encode Categorical Columns before computing demand
    vehicle_map = {'car': 0, 'bike': 1, 'truck': 2, 'cycle': 3}
    traffic_map = {
        'low': 0, 'Low': 0,
        'medium': 1, 'Medium': 1,
        'average': 1,
        'high': 2, 'High': 2
    }
    df['VehicleTypeEncoded'] = df['VehicleType'].map(vehicle_map).fillna(-1).astype(int) # Use -1 for unmapped
    df['TrafficEncoded'] = df['TrafficConditionNearby'].map(traffic_map).fillna(-1).astype(int) # Use -1 for unmapped


    # Define weights for demand components
    weights = {
        'alpha': 1.5,
        'beta': 0.7,
        'gamma': -0.5,
        'delta': 1.2,
        'epsilon': 0.8
    }

    # Compute demand and normalize
    df['RawDemand'] = compute_demand(df, weights)
    # Normalize demand per lot ‚Äî prevents flat scaling across all data
    df['NormalizedDemand'] = df.groupby('SystemCodeNumber')['RawDemand'].transform(normalize_demand)

    # Optional: Add small epsilon to avoid zero-flat prices
    df['NormalizedDemand'] += 1e-3

    # Apply pricing
    df['Price'] = base_price * (1 + lambda_coeff * df['NormalizedDemand'])

    # Clamp price between bounds (optional)
    df['Price'] = df['Price'].clip(lower=5, upper=20)

    return df

# Run if this script is executed directly
if __name__ == "__main__":
    df = pd.read_csv("preprocessed_dataset.csv", parse_dates=['Timestamp'])
    df = demand_pricing_model(df)
    print("Final Normalized Demand:", df['NormalizedDemand'].unique()[:5])


    # Save output
    df.to_csv("demand_pricing_output.csv", index=False)

    # Plot sample pricing
    sample_lot = df['SystemCodeNumber'].unique()[0]
    sample_df = df[df['SystemCodeNumber'] == sample_lot]

    plt.figure(figsize=(12, 4))
    plt.plot(sample_df['Timestamp'], sample_df['Price'], label='Price ($)')
    plt.title(f"Demand-Based Pricing Over Time (Lot {sample_lot})")
    plt.xlabel("Time")
    plt.ylabel("Price ($)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

"""##Model 3‚Äî Competitive Pricing Logic

###New Logic to Add:
* Use Haversine distance to find nearby parking lots (within ~1 km)
* Adjust price based on nearby competitor prices:
* If nearby lots are cheaper ‚Üí consider lowering price
* If nearby lots are full or expensive ‚Üí you can increase your price
* Optional: Suggest rerouting if your lot is full and nearby ones are available


"""

from sklearn.preprocessing import MinMaxScaler
from math import radians, cos, sin, sqrt, atan2
import pandas as pd
import numpy as np

# Haversine distance in kilometers
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Earth radius in km
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2
    return 2 * R * atan2(sqrt(a), sqrt(1 - a))

# Get nearby competitors
def get_nearby_lots(df, lot_id, lat, lon, radius_km=1.0):
    lots = df[['SystemCodeNumber', 'Latitude', 'Longitude']].drop_duplicates()
    nearby = []
    for _, row in lots.iterrows():
        if row['SystemCodeNumber'] == lot_id:
            continue
        distance = haversine(lat, lon, row['Latitude'], row['Longitude'])
        if distance <= radius_km:
            nearby.append(row['SystemCodeNumber'])
    return nearby

# Adjust price based on competitor prices
def adjust_price(base_price, own_price, competitor_prices):
    if not competitor_prices:
        return own_price

    avg_comp_price = np.mean(competitor_prices)

    if own_price > avg_comp_price:
        return own_price - 1  # Reduce to stay competitive
    elif own_price < avg_comp_price:
        return own_price + 1  # Slight bump if underpriced
    return own_price

def compute_demand(df, weights):
    """Compute raw demand score using weighted features"""
    # Ensure encoded columns are numeric
    df['TrafficEncoded'] = pd.to_numeric(df['TrafficEncoded'], errors='coerce').fillna(0)
    vt_weight = pd.to_numeric(df['VehicleTypeEncoded'].map({0: 1.0, 1: 0.6, 2: 1.2, 3: 0.5}), errors='coerce').fillna(0)


    demand = (
        weights['alpha'] * (df['Occupancy'] / df['Capacity']) +
        weights['beta'] * df['QueueLength'] +
        weights['gamma'] * df['TrafficEncoded'] +
        weights['delta'] * df['IsSpecialDay'] +
        weights['epsilon'] * vt_weight
    )
    return demand


def competitive_pricing_model(df, base_price=10, lambda_coeff=0.5):
    df = df.sort_values(['SystemCodeNumber', 'Timestamp']).copy()

    # Encode Categorical Columns before computing demand
    vehicle_map = {'car': 0, 'bike': 1, 'truck': 2, 'cycle': 3}
    traffic_map = {
        'low': 0, 'Low': 0,
        'medium': 1, 'Medium': 1,
        'average': 1,
        'high': 2, 'High': 2
    }
    df['VehicleTypeEncoded'] = df['VehicleType'].map(vehicle_map).fillna(-1).astype(int) # Use -1 for unmapped
    df['TrafficEncoded'] = df['TrafficConditionNearby'].map(traffic_map).fillna(-1).astype(int) # Use -1 for unmapped


    # Demand-based component
    weights = {
        'alpha': 1.5, 'beta': 0.7, 'gamma': -0.5,
        'delta': 1.2, 'epsilon': 0.8
    }


    df['RawDemand'] = compute_demand(df, weights)

    # Normalize demand
    scaler = MinMaxScaler()
    df['NormalizedDemand'] = scaler.fit_transform(df[['RawDemand']])

    # Initial price from demand
    df['InitialPrice'] = base_price * (1 + lambda_coeff * df['NormalizedDemand'])

    # Competitive adjustment
    df['Price'] = 0.0
    for lot_id in df['SystemCodeNumber'].unique():
        lot_df = df[df['SystemCodeNumber'] == lot_id]
        lat, lon = lot_df.iloc[0][['Latitude', 'Longitude']]
        nearby_ids = get_nearby_lots(df, lot_id, lat, lon)

        for i, row in lot_df.iterrows():
            # Get competitor prices at the same timestamp
            competitors = df[
                (df['SystemCodeNumber'].isin(nearby_ids)) &
                (df['Timestamp'] == row['Timestamp'])
            ]

            adjusted = adjust_price(
                base_price=base_price,
                own_price=row['InitialPrice'],
                competitor_prices=competitors['InitialPrice'].tolist()
            )

            # Optional reroute suggestion flag
            reroute = 0
            if row['Occupancy'] >= row['Capacity'] and len(competitors[competitors['Occupancy'] < competitors['Capacity']]) > 0:
                reroute = 1

            df.at[i, 'Price'] = np.clip(adjusted, 5, 20)
            df.at[i, 'RerouteSuggestion'] = reroute

    return df

# Script entry point
if __name__ == "__main__":
    df = pd.read_csv("preprocessed_dataset.csv", parse_dates=['Timestamp'])
    df = competitive_pricing_model(df)
    df.to_csv("competitive_pricing_output.csv", index=False)

    # Visualize one sample lot
    sample_lot = df['SystemCodeNumber'].unique()[0]
    sample_df = df[df['SystemCodeNumber'] == sample_lot]

    plt.figure(figsize=(12, 4))
    plt.plot(sample_df['Timestamp'], sample_df['Price'], label='Price ($)')
    plt.title(f"Competitive Pricing Over Time (Lot {sample_lot})")
    plt.xlabel("Time")
    plt.ylabel("Price ($)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

"""##Pathway Real-Time Simulation"""

!pip install -U pathway

import pathway as pw
import random

# Prepare a streaming CSV from preprocessed data
df = pd.read_csv("preprocessed_dataset.csv", parse_dates=['Timestamp'])

# Handle potential missing values before creating the stream
df['QueueLength'] = pd.to_numeric(df['QueueLength'], errors='coerce').fillna(0)
df['TrafficEncoded'] = pd.to_numeric(df['TrafficEncoded'], errors='coerce').fillna(0)
df['VehicleTypeEncoded'] = pd.to_numeric(df['VehicleTypeEncoded'], errors='coerce').fillna(0)

df.to_csv("input_stream.csv", index=False)

# Define schema explicitly to ensure correct types
input_schema = pw.schema_from_csv("input_stream.csv")
input_schema.QueueLength = pw.Type.FLOAT
input_schema.TrafficEncoded = pw.Type.FLOAT
input_schema.VehicleTypeEncoded = pw.Type.FLOAT
input_schema.IsSpecialDay = pw.Type.INT

# 1Ô∏è‚É£ Simulate streaming input
input_tbl = pw.demo.replay_csv(
    "input_stream.csv",
    schema=input_schema,
    input_rate=5.0  # simulate 5 rows / sec
)

# 2Ô∏è‚É£ Compute occupancy ratio (demonstration)
enriched = input_tbl.with_columns(
    OccupancyRatio=input_tbl.Occupancy / input_tbl.Capacity
)

# üéØ 3Ô∏è‚É£ Insert pricing logic via UDF
@pw.udf
def price_udf(system, capacity, occupancy, qlen, traffic_label, special, vehicle_label, ts):
    try:
        row = pd.DataFrame([{
            'SystemCodeNumber': system,
            'Capacity': capacity,
            'Occupancy': occupancy + random.randint(0, 20),
            'QueueLength': qlen + random.randint(0, 3),
            'TrafficConditionNearby': traffic_label,
            'IsSpecialDay': special,
            'VehicleType': vehicle_label,
            'Latitude': 0.0,
            'Longitude': 0.0,
            'Timestamp': pd.to_datetime(ts)
        }])

        result = demand_pricing_model(row)

        return float(result['Price'].values[0])
    except Exception as e:
        print("UDF Error:", e)
        return 10.0

priced = input_tbl.with_columns(
    Price=price_udf(
        input_tbl.SystemCodeNumber,
        input_tbl.Capacity,
        input_tbl.Occupancy,
        input_tbl.QueueLength,
        input_tbl.TrafficConditionNearby,  # raw label
        input_tbl.IsSpecialDay,
        input_tbl.VehicleType,             # raw label
        input_tbl.Timestamp
    )
)



# 4Ô∏è‚É£ Write to live output
pw.io.jsonlines.write(priced, filename="streamed_prices.jsonl")

# 5Ô∏è‚É£ Execute the pipeline

pw.run()

!head streamed_prices.jsonl

!wc -l input_stream.csv

!wc -l streamed_prices.jsonl

"""##Real-time-like Bokeh dashboard"""

import json

valid_lines = []
with open("streamed_prices.jsonl", "r") as infile:
    for line in infile:
        try:
            json.loads(line)
            valid_lines.append(line)
        except json.JSONDecodeError:
            print("‚ùå Skipped malformed line:", line.strip())

# Write clean file
with open("streamed_prices_clean.jsonl", "w") as outfile:
    outfile.writelines(valid_lines)

print(f"‚úÖ Cleaned {len(valid_lines)} lines into 'streamed_prices_clean.jsonl'")

from bokeh.plotting import figure, show, output_notebook
from bokeh.models import ColumnDataSource, Select
from bokeh.layouts import column
from bokeh.io import push_notebook
import ipywidgets as widgets
import random

# Enable Bokeh in notebook
output_notebook()

# Step 1: Load streamed data
df = pd.read_json("streamed_prices_clean.jsonl", lines=True)
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df = df.sort_values(['SystemCodeNumber', 'Timestamp'])

# Step 2: Prepare dropdown for lot selection
unique_lots = df['SystemCodeNumber'].unique().tolist()
initial_lot = unique_lots[0]

def create_source(lot):
    lot_df = df[df['SystemCodeNumber'] == lot]
    return ColumnDataSource(lot_df)

source = create_source(initial_lot)

# Step 3: Create Bokeh figure
p = figure(x_axis_type="datetime", height=300, title=f"Price Trend - {initial_lot}")
p.line('Timestamp', 'Price', source=source, line_width=2, color='green')
p.xaxis.axis_label = "Time"
p.yaxis.axis_label = "Price ($)"

# Step 4: Dropdown to update lot
def update_lot(attr, old, new):
    new_source = create_source(new)
    source.data = dict(new_source.data)
    p.title.text = f"Price Trend - {new}"
    push_notebook()

dropdown = widgets.Dropdown(options=unique_lots, value=initial_lot, description='Lot:')
dropdown.observe(lambda change: update_lot(None, None, change['new']), names='value')

# Step 5: Show interactive plot
show(p, notebook_handle=True)
display(dropdown)